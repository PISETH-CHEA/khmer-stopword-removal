{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce45b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook 01: Khmer Text Segmentation Exploration\n",
    "# Objective: Explore raw Khmer corpus, verify segmentation quality, and understand tokenization patterns.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.preprocessing.text_loader import load_corpus\n",
    "from src.segmentation.segmenter_interface import KhmerSegmenter\n",
    "from src.preprocessing.unicode_normalizer import normalize_text\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084c6807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "raw_dir = \"../data/raw\"\n",
    "corpus = load_corpus(raw_dir)\n",
    "\n",
    "print(f\"=== CORPUS OVERVIEW ===\")\n",
    "print(f\"Number of documents: {len(corpus)}\")\n",
    "for doc_id, content in corpus.items():\n",
    "    print(f\"{doc_id}: {len(content)} characters, {len(content.split())} word-like tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e4b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize segmenter\n",
    "segmenter = KhmerSegmenter()\n",
    "\n",
    "# Sample segmentation examples\n",
    "sample_texts = [\n",
    "    corpus['khmer_articles.txt'][:200],\n",
    "    corpus['khmer_news_corpus.txt'][:200],\n",
    "    corpus['khmer_corpus.txt'][:200]\n",
    "]\n",
    "\n",
    "print(\"=== SEGMENTATION EXAMPLES ===\")\n",
    "for i, text in enumerate(sample_texts):\n",
    "    normalized = normalize_text(text)\n",
    "    segmented = segmenter.segment(normalized)\n",
    "\n",
    "    print(f\"\\n--- Sample {i+1} ---\")\n",
    "    print(f\"Original (first 100 chars): {text[:100]}...\")\n",
    "    print(f\"Segmented (first 20 tokens): {' | '.join(segmented[:20])}\")\n",
    "    print(f\"Token count: {len(segmented)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb846aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze token length distribution\n",
    "all_tokens = []\n",
    "for doc_id, text in corpus.items():\n",
    "    normalized = normalize_text(text)\n",
    "    segmented = segmenter.segment(normalized)\n",
    "    all_tokens.extend(segmented)\n",
    "\n",
    "token_lengths = [len(token) for token in all_tokens]\n",
    "\n",
    "print(f\"=== TOKEN STATISTICS ===\")\n",
    "print(f\"Total tokens: {len(all_tokens)}\")\n",
    "print(f\"Unique tokens: {len(set(all_tokens))}\")\n",
    "print(f\"Average token length: {np.mean(token_lengths):.2f} characters\")\n",
    "print(f\"Median token length: {np.median(token_lengths):.2f} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3b3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot token length distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(token_lengths, bins=range(1, 21), edgecolor='black')\n",
    "plt.title('Distribution of Khmer Token Lengths')\n",
    "plt.xlabel('Token Length (characters)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c9e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common tokens\n",
    "token_counts = Counter(all_tokens)\n",
    "most_common = token_counts.most_common(20)\n",
    "\n",
    "print(\"=== MOST COMMON TOKENS ===\")\n",
    "for token, count in most_common:\n",
    "    print(f\"{token}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63115469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 20 tokens with Khmer font support\n",
    "tokens, counts = zip(*most_common)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Use a font that supports Khmer script\n",
    "plt.rcParams['font.family'] = 'Khmer OS'  # or another Khmer-supporting font like 'Khmer OS System', 'Khmer OS Siemreap'\n",
    "\n",
    "plt.barh(range(len(tokens)), counts)\n",
    "plt.yticks(range(len(tokens)), tokens)\n",
    "\n",
    "# Ensure the font is applied to the labels\n",
    "for label in plt.gca().get_yticklabels():\n",
    "    label.set_fontname('Khmer OS')\n",
    "\n",
    "plt.xlabel('Frequency')\n",
    "plt.title('Top 20 Most Frequent Khmer Tokens')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()  # Adjust layout to prevent label cutoff\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe3d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Observations\n",
    "print(\"\"\"\n",
    "=== KEY OBSERVATIONS ===\n",
    "1. Segmentation Quality: khmer-nltk successfully tokenized Khmer text without explicit spacing\n",
    "2. Token Length: Most tokens are 1-5 characters (typical for Khmer script)\n",
    "3. High-frequency words: Common function words appear at the top of frequency list\n",
    "4. Corpus Variation: Different document types show varying token distributions\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WIR (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
